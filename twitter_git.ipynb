{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twitter data analysis\n",
    "\n",
    "Two projects are built using Twitter API:\n",
    "1. Extracting trending hashtags and their volume based on location. ALso, visualising the appearance of trending hashtags at different locations.\n",
    "\n",
    "2. Extracting and visulaising the locations where a specific keyword or hashtag is trending, to capture the popularity or awareness of any specific thing (e.g. product, policy, agenda, technology etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame,Series \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II. Connect with twitter\n",
    "#### Input these information: \n",
    " - access_token=\"enter value here\"\n",
    " - access_token_secret=\"enter value here\"\n",
    " - api_key=\"enter value here\"\n",
    " - api_key_secret=\"enter value here\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "access_token=\"\"\n",
    "access_token_secret=\"\"\n",
    "api_key=\"\"\n",
    "api_key_secret=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth=tweepy.OAuthHandler(consumer_key=api_key,consumer_secret=api_key_secret)\n",
    "auth.set_access_token(access_token,access_token_secret)\n",
    "api=tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Project 1 :*\n",
    "\n",
    "### 1. Get where on earth id (woeid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "woeid_csv=pd.read_csv('...\\geoplanet_places_7.10.0.csv',sep='\\t')\n",
    "woeid_country=woeid_csv[woeid_csv['PlaceType']=='Country']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Get trending hashtags form a specific location\n",
    "       - api.get_place_trend(woeid) gives the trending tweets in JSON format\n",
    "       - Trending hashtags and number of its appearance (Volume) at a specific location were extracted\n",
    "       - Trending hashtags of India, USA, France, UK and Ausralia were extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_info=woeid_country[woeid_country['Name'].isin(['India','United States','France','United Kingdom','Australia'])]\n",
    "hashtags_all=DataFrame()\n",
    "for x in range(len(country_info)):\n",
    "   woeid=str(country_info.iloc[x,0])\n",
    "   country_name=str(country_info.iloc[x,2])\n",
    "   trend_result=api.get_place_trends(woeid)\n",
    "   trendlist1=[]\n",
    "   trendlist2=[]\n",
    "   for trend in trend_result[0][\"trends\"][:10]:\n",
    "        ##print(trend[\"name\"])\n",
    "        ##print(trend[\"tweet_volume\"])\n",
    "        trendlist1.append(trend[\"name\"])\n",
    "        trendlist2.append(trend[\"tweet_volume\"])\n",
    "        hashtags=DataFrame(list(zip(trendlist1,trendlist2)),columns=['hashtag','volume'])\n",
    "        hashtags.sort_values(by='volume',ascending=False,inplace=True)\n",
    "        hashtags.insert(1,'country',country_name)\n",
    "   hashtags_all=hashtags_all.append(hashtags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Get common hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_hashtag=hashtags_all[hashtags_all.duplicated('hashtag',keep = False)]\n",
    "duplicate_hashtag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Plot trending common hashtags and their corresponding volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "plt.xticks(rotation=0)\n",
    "sns.barplot(data=duplicate_hashtag,x='hashtag',y='volume',hue='country')\n",
    "plt.xlabel('Hashtag')\n",
    "plt.ylabel('Volume')\n",
    "plt.legend( loc='upper right',title='Country')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Project 2 :*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Get the location of the trending keyword \n",
    "       - Extract the location of tweets and the \n",
    "       - This query searches for 100 recent popular tweets that contain the input word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter the keyword:cancelo\n"
     ]
    }
   ],
   "source": [
    "choice=input('enter the keyword:')\n",
    "tweets=tweepy.Cursor(api.search_tweets,q=choice,result_type='popular').items(100)\n",
    "tweet_loc=[]\n",
    "totaltweets=[]\n",
    "for tweet in tweets:\n",
    "    tweet_loc.append(tweet.user.location)\n",
    "tweet_loc_df=DataFrame((tweet_loc),columns=['location'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Get the locations in a dataframe and visualise using bar plot\n",
    "       - Replace rows with no value\n",
    "       - Group the rows of dataframe based on the number of times a keyword has appeared at a specific location \n",
    "       - Sort the dataframe based on the tweet count (highest to lowest) and plot top 30 locations using seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_loc_df['location'].replace('', np.nan, inplace=True)\n",
    "tweet_loc_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_loc_df['Counts'] = tweet_loc_df.groupby('location')['location'].transform('count')\n",
    "tweet_loc_vol=tweet_loc_df.sort_values(by='Counts', ascending=False).iloc[0:30,:]\n",
    "tweet_loc_trend=tweet_loc_vol.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "plt.xticks(rotation=90)\n",
    "sns.barplot(x='location',y='Counts',data=tweet_loc_trend,palette ='plasma')\n",
    "plt.xlabel('Location')\n",
    "plt.ylabel('Counts')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
